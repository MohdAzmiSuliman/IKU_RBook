# Complex Sampling Design in NHMS

```{r}
#| label: setup
#| echo: false

pacman::p_load(tidyverse)
```

## Why Complex Sampling Design?

Surveys are essential for understanding population characteristics, offering a more efficient and resource-friendly alternative to censuses. Censuses, aiming to collect data from every individual within a population, are historically resource-intensive. In contrast, surveys, whether conducted by governments or researchers, enable effective population inferences with less expenditure.

Simple random sampling, while a traditional gold standard for its straightforward approach and unbiased estimates, often falls short in achieving comprehensive representativeness, particularly in diverse populations. This limitation becomes apparent in the context of the National Health and Morbidity Survey (NHMS), where both national and state-level representativeness are crucial. Simple random sampling might not adequately represent all geographic areas, especially when population densities and distributions vary significantly across different states. This could lead to over representation of more populous areas while leaving less populous regions under-represented.

Furthermore, this sampling method might not effectively capture the diversity within minority groups, as their smaller numbers in the overall population reduce the likelihood of their selection in a simple random sample. To overcome these challenges, NHMS employs more intricate sampling designs like stratified sampling. By dividing the population into distinct strata based on states or regions, and further considering sub-groups within these strata, it ensures that both geographic areas and minority groups are appropriately represented. Although these complex sampling designs introduce potential biases in selection probabilities and are more challenging to implement, they are indispensable for achieving the depth of representativeness required for national health assessments and policy planning.

One of the significant advantages of complex sampling designs is their feasibility without a comprehensive population list, focusing instead on broader stratifications like specific localities, simplifying the sampling process.

\newpage

### Benefits of Complex Sampling Design

The National Health and Morbidity Survey (NHMS), conducted by the Institut Kesihatan Umum (IKU), benefits extensively from complex sampling designs, showcasing several advantages:

1.  **Cost Efficiency**: By clustering samples within selected strata or areas, operational costs are notably reduced, obviating the need to cover extensive and potentially scattered geographical locations.

2.  **Enhanced Representativeness**: Stratification techniques ensure the sample accurately reflects specific subgroups or geographic areas, improving the survey's overall representativeness and reliability.

3.  **Data Analysis Advantages**: Complex sampling designs facilitate the adjustment of sampling weights, enabling the generation of accurate national or state-level estimates. Furthermore, they support comprehensive subgroup analyses, ensuring sufficient statistical power.

### Challenges in Implementing Complex Sampling Design

Despite their benefits, complex sampling designs require meticulous planning and sophisticated analytical techniques. These designs necessitate accounting for factors like clustering and weighting, demanding specialised expertise for both the sample's design and subsequent data analysis.

### Example: Sampling Probability of a Sabahan

Problem: Consider a hypothetical scenario within a diverse group of 100 people, composed of 60% Malay, 20% Chinese, 15% Indian, and an additional 5% from other ethnic backgrounds, including 1% Sabahan. How sure are we, than when we randomly select 10 people from the group, at least one of the 10 people will be a Sabahan?  

Answer: To calculate the probability of selecting at least one Sabahan in a 10-person sample, one might initially consider the likelihood of not choosing a Sabahan and subtract this figure from 1. With 99 of the 100 individuals not being Sabahan, the probability of not selecting a Sabahan in a single attempt is 99/100. Over 10 independent selections, this probability becomes (99/100)\^10. Consequently, the probability of selecting at least one Sabahan is 1 - (99/100)\^10, equating to approximately 9.56%. This calculation suggests a close to 10% chance that the sample will include at least one Sabahan.  

Or in other word, since minorities were in fact had lower percentage, when we sample our population, we might even did not get the minorities in our sample!.  

\newpage

## Practical

In complex survey analysis using the `survey::` package in R, it's crucial to account for the design aspects of the survey beyond just the outcome variables and covariates. This includes specifying: 

```{r}
#| echo: false
#| tbl-cap: "Required Information for Complex Sampling Design"

tribble(~`Required Information/Specification`, ~`Common NHMS Variable Name`, 
        "Cluster IDs (PSU)", "EB ID", 
        "Strata", "State.Strata, State.wt", 
        "Sampling Weight", "ADW, weight_final, weight") %>% 
  gt::gt()
```


### Setup Project

1.  Setup your project
2.  Copy the NHMS dataset into the working directory
3.  Create Quarto document
    -   update the YAML metadata to make the document self-contained

```{r}
#| echo: true
#| eval: false

---
title: "Sesi 4 - NHMS"
format:
  html:
    embed-resources: true
---

```

### Analysis

#### Setup

0.  Understand the dataset context
    -   In this practical, the example was shown using NHMS NCD 2019's cholesterol dataset.
    -   Two outcome will be selected
        -   Categorical Type: known hypercholesterolaemia status (column `known_chol`)
        -   Numerical Type: capillary total cholesterol level (column `u303`)

@.  Import Dataset
    -   On the `Files` pane, click on the spps .sav file
    -   Select `Import Dataset...`
    -   Copy the code into the r code chunk
    -   add function `as_factor(_)` to convert labelled code

\newpage

```{r}
#| output: false
#| echo: fenced

library(tidyverse)
library(haven)

nhms19ds <- read_sav("nhms19ds.sav") %>% 
  as_factor()

nhms19ds
```


::: {.callout-note}
there are 40 columns in the dataset, hence the dataset is not shown here. 
:::



@. Briefly (or in detail, up to you), explore the dataset.
    -   Identify the outcome variable
        -   data type: numerical, character or factor?
        -   any missing data
    -   Identify the complex sampling related variable: 
        -   the cluster ids
        -   the strata 
        -   the sampling weight



::: {.callout-tip}
some packages and functions that offer a quick data exploration:  
    -   `skimr::` package: `skim(_)` function.  
    -   `summarytools::` package: `dfSummary(_)` function.  
:::


```{r}
#| eval: false
#| echo: fenced

library(skimr)

nhms19ds %>% 
  select(known_chol, u303) %>% 
  skim()
```


\newpage
\KOMAoptions{usegeometry, paper=landscape,pagesize}
\recalctypearea
\newgeometry{right=25mm,left=25mm,top=25mm,bottom=25mm}

```{r}
#| echo: false
#| layout-ncol: 2
#| tbl-cap: "NHMS NCD 2019 - Cholesterol Module Dataset: Variables List"

library(labelled)
library(gt)

tibble(varname = names(nhms19ds), 
       varlab = get_variable_labels(nhms19ds)) %>% 
  unnest(cols = varlab, keep_empty = T) %>% 
  slice(., 1:20) %>% 
  gt() %>% 
  cols_label(varname = "Variable Name", 
             varlab = "Variable Label") %>%
  fmt_missing(missing_text = "_no label_")

tibble(varname = names(nhms19ds), 
       varlab = get_variable_labels(nhms19ds)) %>% 
  unnest(cols = varlab, keep_empty = T) %>% 
  slice(., 21:40) %>% 
  gt() %>% 
  cols_label(varname = "Variable Name", 
             varlab = "Variable Label") %>%
  fmt_missing(missing_text = "_no label_")
```

\newpage
\KOMAoptions{paper=portrait,pagesize}
\recalctypearea
\restoregeometry

```{r}
#| echo: false

library(skimr)

nhms19ds %>% 
  select(known_chol, u303) %>% 
  skim()
```

::: {.callout-warning}
- there are missing values in the outcome variable `known_chol`. while is it not a must to remove sample with no outcome, as the analysis will automatic remove sample with no outcome using `na.rm = T` parameter, it is advisable to remove any sample that do not have the outcome. 
- the outcome variable of capillary total cholesterol was in categorical type. we need to convert it to numerical type
:::


::: {.callout-tip}
later in complex sampling design analysis, the analysis accept the variable outcome (i.e. the `known_chol`) variable in either numeric or factor type. but binary type is preferable
:::


@. In this practical we will make some data wrangling
    -   remove missing outcome
    -   transform factor type to numerical binary type

```{r}
#| echo: fenced

nhms19ds <- nhms19ds %>% 
  as_factor() %>% 
  filter(!is.na(known_chol)) %>% 
  mutate(known_cholN = as.numeric(known_chol)-2,
         u303 = as.numeric(as.character(u303)))
```

\newpage

::: {.callout-note}
The variable `known_col` have there levels, which can be check using `levels(_)` function:  `levels(nhms19ds$known_chol)`. When converted to numeric using `as.numeric(_)` function, the `known_chol` value was either `1` (correspond to NA), `2` (correspond to No) and `3` (correspond to Yes), thus the value need to minus 2, so that `No` is correspond to value `0` and `Yes` is correspond with value `1`.  
\newline
the conversion can be check by looking at both the variable

```{r}
#| eval: false
#| echo: fenced

nhms19ds %>% 
  select(known_chol, known_cholN)
```
:::

@. Specifying the Complex Sampling Design
    -   Add options at the top of Quarto file
    -   These option is to handle in which if there is single PSU within strata or domains
    ```{r}
    #| echo: fenced
    
    library(survey)
    
    options(survey.lonely.psu = 'adjust', 
            survey.adjust.domain.lonely = TRUE)
    ```
    -   Unweighted Design
        -   cluster ids set as 1 (i.e., no clustering)
        -   weight as 1 (i.e., same probability)
    ```{r}
    #| echo: fenced
    
    nhms_unwdsg <- svydesign(id = ~1, 
                             weights = ~1, 
                             data = nhms19ds)
    ```
    \newpage
    -   we can use function `summary(_)` to view our complex sample design
    ```{r}
    summary(nhms_unwdsg)
    ```
    -   in unweighted design, the probability for sample range from 1 to 1.
    -   Weighted Design
        -   cluster `id` set as the PSU (commonly the variable `ebid`)
        -   `strata` set as the stratification. since most NHMS applied two stage of stratification, the strata must include both 1st stage and 2nd stage (commonly the variable `state_st`)
        -   `weights` set as the sampling weight
        -   Note that parameter `nest = T` to ensure that the cluster is nested within the specified strata
    ```{r}
    #| echo: fenced
    
    nhms_surdsg <- svydesign(id = ~ebid, 
                             strata = ~state_st, 
                             weights = ~wtfinal_ncd, 
                             data = nhms19ds, 
                             nest = T)
    ```
    -   we can use function `summary(_)` to view our complex sample design
    \newpage
    ```{r}
    #| echo: fenced
    options(width = 70) # the output width limit

    summary(nhms_surdsg)
    ```
    -   in weighted design summary, several info were given
        -   the sampling probabilities. in this dataset, each of the sample have probability from 0.00001 to 0.12
        -   the number of strata, number of sample in each of the strata and number of PSU (EB) in each strata. in this dataset, there are total 30 strata (13 states + 3 federal territories, with each state have 2 locality urban and rural).

#### Count the unweighted sample

1. To count the number of sample, we will use function `svymean(_`) from `survey::`. 
    -   the outcome variable can be either factor type, or if it in numerical type, it must be binary 0-1 number.
    -   to estimate the number of sample, we will use the unweighed design.
    -   the `x =` parameter must be in formula form with `~` (tilde) symbol before the variable name, i.e. `~known_chol`.

2. this is if we want to use the original factor type.

```{r}
#| echo: fenced

svytotal(x = ~known_chol, 
         design = nhms_unwdsg, 
         na.rm = T)
```

3. this is if we want to use the converted to binary 0-1 numerical type. noticed the output differences.

```{r}
#| echo: fenced

svytotal(x = ~known_cholN, 
         design = nhms_unwdsg, 
         na.rm = T)
```


::: {.callout-note}
Note 1: noticed that parameter `na.rm =` were set as T (TRUE). this is so that any sample with missing at parameter `x =` (i.e. the `known_chol`) will be removed.  
\newline
Note 2: From this point forward, I'll use `known_cholN` variable (the binary 0-1 numerical type) as the outcome. You are feel free to use the original factor type, and explore as you wish.
:::

#### Estimating the estimated population

1. to estimate total number of population that have the outcome (i.e., `known_cholN`), same formula is used, with changes at the design used, i.e. the weighted design

```{r}
#| echo: fenced

svytotal(x = ~known_cholN, 
         design = nhms_surdsg, 
         na.rm = T)
```


#### Estimating Prevalence

0. Estimating the prevalence using the function of `svymean(_)` from `survey::` package.
    -   if the outcome variable is factor type, both original factor type and converted numerical type can be used.
        -   if original factor type is used, prevalence for both `No` and `Yes` will be estimated.
        -   if the outcome have three or more levels, using original factor type is preferable.
        -   when using the binary 0-1 numerical type (i.e., the `known_cholN`), `svymean(_)` will calculate prevalence by calculating how many `1` since `0` does not have value.

1. Using function `svymean(_)` to calculate 

```{r}
#| echo: fenced

svymean(x = ~known_cholN, 
        design = nhms_surdsg, 
        na.rm = T)
```

\newpage

#### Estimating Confidence Interval for Prevalence

1. To calculate the confidence interval for prevalence, function `svyciprop(_)` from package `survey::` will be used.
    -   Generally, a generic function `confint(_)` can be used to calculate the confident interval for model parameter. 
    -   In R however, the function will treat proportion as mean of binary outcomes. While treating proportion as mean of binary outcomes is reasonable accepted to calculate the prevalence, however, when calculate the CI, it is preferable to treat apply logit transformation and transformed back to the original scale
    -   the default method used in `svyciprop(_)` function is "logit"
    -   however, to replicate result from SPSS and SUDAAN, the method parameter need to change to "xlogit"


```{r}
#| echo: fenced

svyciprop(formula = ~known_cholN, 
          design = nhms_surdsg, 
          method = "xl") %>% 
  attr(., "ci")
```
::: {.callout-note}
- function `attr(_)` is used to pull the attribute from the object (i.e., the output of the `svyciprop(_)` function), while the parameter `"ci"` in the `attr(_, "ci")` function is to pull the CI from the `svyciprop(_)`
:::


#### Estimating the Unweighted Sample Proportion

\noindent Can you calculated the sample proportion using the same function?.  

::: {.callout-tip}
Hint:  

1. Sample Proportion = Unweighted Proportion.
2. Unweighted design vs. Weighted design.
:::


#### Estimating by Subpopulation

1. To estimates by subpopulation, we use `svyby(_)` function

2. Estimating the unweighted count by locality (urban vs rual)
    -   Don't forget to use the unweighted design

```{r}
#| echo: fenced

svyby(formula = ~known_cholN, 
      by = ~strata_gp, 
      design = nhms_unwdsg, 
      FUN = svytotal, 
      na.rm.all = T)

```

3. Estimating the estimated population by locality (urban vs rual)

```{r}
#| echo: fenced

svyby(formula = ~known_cholN, 
      by = ~strata_gp, 
      design = nhms_surdsg, 
      FUN = svytotal, 
      na.rm.all = T)
```


4. Estimating the prevalence by locality (urban vs rual)

```{r}
#| echo: fenced

svyby(formula = ~known_cholN, 
      by = ~strata_gp, 
      design = nhms_unwdsg, 
      FUN = svymean, 
      na.rm.all = T)
```

5. Estimating the prevalence CI by locality (urban vs rual).
    - unfortunately, `svyciprop(_)` can't be used with `svyby(_)` function.
    - to estimate the CI, we need to subset the sample, to only the sub-population.

::: {.callout-warning}
This however, will affect the degree of freedom (df). thus, we need to specified the df in the subset analysis, using the df of the overall design. to achieve this, add parameter `df = degf(design)`, where the design is the overall design
:::

```{r}
#| echo: fenced

nhms_surdsg_urban <- subset(nhms_surdsg, 
                            strata_gp == "Urban") 

svyciprop(formula = ~known_cholN, 
          design = nhms_surdsg_urban, 
          method = "xl", 
          df = degf(nhms_surdsg)) %>% 
  attr(., "ci")
```
\noindent alternatively, we can create custom function \newline (the custom function code is shown next page) 

```{r}
#| echo: false

# create a svyby-like function specific for svyciprop
svyciprop_by <- function(x, by, design, 
                         df = NULL, method = NULL) {
  # extract the levels in by
  by_var <- all.vars(by)[1]
  by_data <- model.frame(by, data = design$variables)
  by_levels <- sort(unique(by_data[[by_var]]))
 
  # run the svyciprop() functions on each levels in by
  calculate_ci <- function(stratum) {
    subset_design <- 
      subset(design, 
             design$variables[[by_var]] == stratum)
    # Use provided df or default to subset design df
    df_to_use <- if (is.null(df)) degf(subset_design) else df
    result <- svyciprop(x, design = subset_design, 
                        method = method, df = df_to_use)
    return(attr(result, "ci"))
  }
  
  # tabulate the result
  ci_results <- lapply(by_levels, calculate_ci)
  results <- data.frame(subset = by_levels, 
                        ci = do.call(rbind, ci_results))

  return(results)
}
```


```{r}
#| echo: fenced

svyciprop_by(x = ~known_cholN, 
             by = ~strata_gp, 
             design = nhms_surdsg, 
             df = degf(nhms_surdsg), 
             method = "xl")
```

\newpage 

\noindent the custom function code

```{r}
#| echo: fenced

# create a svyby-like function specific for svyciprop
svyciprop_by <- function(x, by, design, 
                         df = NULL, method = NULL) {
  # extract the levels in by
  by_var <- all.vars(by)[1]
  by_data <- model.frame(by, data = design$variables)
  by_levels <- sort(unique(by_data[[by_var]]))
 
  # run the svyciprop() functions on each levels in by
  calculate_ci <- function(stratum) {
    subset_design <- 
      subset(design, 
             design$variables[[by_var]] == stratum)
    # Use provided df or default to subset design df
    df_to_use <- if (is.null(df)) degf(subset_design) else df
    result <- svyciprop(x, design = subset_design, 
                        method = method, df = df_to_use)
    return(attr(result, "ci"))
  }
  
  # tabulate the result
  ci_results <- lapply(by_levels, calculate_ci)
  results <- data.frame(subset = by_levels, 
                        ci = do.call(rbind, ci_results))

  return(results)
}
```

\vspace{10pt}

::: {.callout-note}
this custom function can be simplified, but i make it more general so it can be use to other too.
:::


#### Total Sample and Estimated Population

\noindent Can you try calculate the total sample? Using the example from calculating the total number sample with the outcome. 

\noindent The tutorial on estimated total population will be cover in Bonus II: Population Pyramid part

## Bonus I: Regression (Linear Regression & Logistic Regression)

### Logistic Regression

#### Simple Logistic Regression

```{r}
#| echo: fenced

svyglm(known_chol ~ strata_gp, 
       nhms_surdsg, 
       family = quasibinomial) %>% 
  summary()
```

\newpage

#### Multiple Logistic Regression

```{r}
#| echo: fenced

svyglm(known_chol ~ strata_gp + A2101 + A2108_3grp, 
       nhms_surdsg, 
       family = quasibinomial) %>% 
  summary()
```


\newpage

### Linear Regression

#### Simple Linear Regression

```{r}
#| echo: fenced

svyglm(u303 ~ strata_gp, 
       nhms_surdsg, 
       family = gaussian) %>% 
  summary()
```

\newpage

#### Multiple Linear Regression

```{r}
#| echo: fenced
options(width = 70) # the output width limit

svyglm(u303 ~ strata_gp+ A2101 + A2108_3grp, 
       nhms_surdsg, 
       family = gaussian) %>% 
  summary()
```

\newpage

## Bonus II: Mapping the Prevalence

We can map our prevalence.  

1. save the prevalence by state into object to be used later

```{r}
#| echo: fenced

kcprev_state <- svyby(formula = ~known_cholN, 
                      by = ~state, 
                      design = nhms_surdsg, 
                      FUN = svymean, 
                      na.rm.all = T) %>% 
  as_tibble()

kcprev_state
```

2. download the state map (geojson file) from DOSM github page

```{r}
#| echo: fenced
#| eval: false

download.file(
  url = "https://raw.githubusercontent.com/dosm-malaysia/data-open/main/datasets/geodata/administrative_1_state.geojson",
  destfile = "administrative_1_state.geojson",
  mode = "wb")
```

::: {.callout-important}
dosm github link to download the map dataset: https://raw.githubusercontent.com/dosm-malaysia/
data-open/main/datasets/geodata/administrative_1_state.geojson
:::

3. in R, map files like geojson and shp file is manipulated using `sf::` package
    -   load sf package, if not available, please install first.

```{r}
#| echo: fenced

library(sf)
```


4. convert the geojson file and save in r object.
    -   in the same time, we can do some data wrangling, to ensure the name of state in dosm dataaset and our dataset is consistent.
    
```{r}
#| echo: fenced

my_state_sf <- read_sf("administrative_1_state.geojson") %>% 
  arrange(code_state) %>% 
  mutate(state = fct_recode(state, 
                            "P. Pinang" = "Pulau Pinang", 
                            "N. Sembilan" = "Negeri Sembilan", 
                            "WP Kl" = "W.P. Kuala Lumpur", 
                            "WP Putrajaya" = "W.P. Putrajaya", 
                            "WP Labuan" = "W.P. Labuan"))
```

5. Join both prevalence by state result and dosm state map.
    -   the combined dataset need to convert to sf object

```{r}
#| echo: fenced
#| eval: false

kcprev_state_mapds <- left_join(kcprev_state, my_state_sf) %>% 
  st_as_sf()

kcprev_state_mapds
```

::: {.callout-note}
any sf item must have geometry column, which contain the information of the location
:::


\newpage

```{r}
#| echo: false

kcprev_state_mapds <- left_join(kcprev_state, my_state_sf) %>% 
  st_as_sf()

kcprev_state_mapds
```

6. we can then plot the prevalence using ggplot


```{r}
#| echo: fenced
#| eval: false

CholPrevMalMap <- kcprev_state_mapds %>% 
  ggplot(aes(fill = known_cholN))
```


```{r}
#| echo: false

CholPrevMalMap <- kcprev_state_mapds %>% 
  ggplot(aes(fill = known_cholN)) + 
  geom_sf() + 
  scale_y_continuous(expand = c(0,0))

ggsave("CholPrevMalMap.png", CholPrevMalMap, height = 4, width = 9)
```

![](CholPrevMalMap.png)


\newpage

## Bonus III: Population Pyramid:

Despite weight adjustment which include post-stratification, the total estimated population may differ from the original population. Here, plotting population pyramid can help to compare NHMS estimated population and DOSM 2019 Population

1. Download the DOSM Population 2019 from DOSM opendata

```{r}
#| echo: fenced
#| eval: false

download.file(
  url = "https://storage.dosm.gov.my/population/population_malaysia.parquet",
  destfile = "population_malaysia.parquet",
  mode = "wb")
```

::: {.callout-important}
dosm open website to download the dataset:  
https://open.dosm.gov.my/data-catalogue/population_malaysia
:::

2. Import downloaded dataset and wrangle it
    -   to exclude data not required
    -   to make data "compatible" with our NHMS dataset

::: {.callout-note appearance="simple"}
the data wrangling code is in the next page
:::


```{r}
#| echo: false

library(arrow)
dosmpop19 <- read_parquet("population_malaysia.parquet") %>% 
  filter(date == "2019-01-01",             # to get 2019 population only
         sex != "overall_sex",             # exclude overall
         ethnicity == "overall_ethnicity", # exclude overall
         age != "overall_age") %>%         # exclude overall
  rename("gender" = "sex") %>% 
  mutate(type = "dosm",
         gender = fct_recode(gender, 
                             "Male" = "male",
                             "Female" = "female"), 
         gender = fct_relevel(gender, "Male"),
         age_grp = case_when(age %in% c("75-79", 
                                        "80-84", 
                                        "85+") ~ "75+", 
                             .default = age), 
         age_grp = fct_relevel(age_grp, 
                               "0-4", "5-9", "10-14", 
                               "15-19", "20-24", "25-29", 
                               "30-34", "35-39", "40-44", 
                               "45-49", "50-54", "55-59", 
                               "60-64", "65-69", "70-74", 
                               "75+"),
         population = population * 1000) %>% 
  select(-c(date, state, ethnicity, age)) %>% # not required 
  group_by(gender, age_grp, type) %>% 
  summarise(population = sum(population, na.rm = T)) %>% 
  ungroup()
```

```{r}
#| echo: fenced

dosmpop19
```

```{r}
#| echo: fenced

library(arrow)
dosmpop19 <- read_parquet("population_malaysia.parquet") %>% 
  filter(date == "2019-01-01",             # to get 2019 population only
         sex != "overall_sex",             # exclude overall
         ethnicity == "overall_ethnicity", # exclude overall
         age != "overall_age") %>%         # exclude overall
  rename("gender" = "sex") %>% 
  mutate(type = "dosm",
         gender = fct_recode(gender, 
                             "Male" = "male",
                             "Female" = "female"), 
         gender = fct_relevel(gender, "Male"),
         age_grp = case_when(age %in% c("75-79", 
                                        "80-84", 
                                        "85+") ~ "75+", 
                             .default = age), 
         age_grp = fct_relevel(age_grp, 
                               "0-4", "5-9", "10-14", 
                               "15-19", "20-24", "25-29", 
                               "30-34", "35-39", "40-44", 
                               "45-49", "50-54", "55-59", 
                               "60-64", "65-69", "70-74", 
                               "75+"),
         population = population * 1000) %>% 
  select(-c(date, state, ethnicity, age)) %>% # not required 
  group_by(gender, age_grp, type) %>% 
  summarise(population = sum(population, na.rm = T)) %>% 
  ungroup()
```


2. Calculate Total NHMS Estimated Population
    -   this require a bit of a work, since we want to calculate all sample
    -   one way of doing it, is by create a new column, with value of `1`
    -   this new column need to be done in the original dataset, thus a new survey design need to be constructed
    - then we can count the unweighted count and the estimated population, by age group and gender, using `svyby(_)` function
    - save the estimated population to an R object to used later

```{r}
#| echo: fenced

nhms19ds_all <- nhms19ds %>% 
  mutate(cholall = 1)
```

```{r}
#| echo: fenced

nhms_surdsg_all <- svydesign(id = ~ebid, 
                             strata = ~state_st, 
                             weights = ~wtfinal_ncd, 
                             data = nhms19ds_all, 
                             nest = TRUE)

nhmspop19 <- svyby(formula = ~cholall, 
                   by = ~A2104_grp+A2101, 
                   design = nhms_surdsg_all, 
                   FUN = svytotal) %>% 
  as_tibble() %>% 
  rename("gender" = "A2101", 
         "age_grp" = "A2104_grp",
         "population" = "cholall") %>% 
  mutate(type = "nhms", 
         age_grp = fct_recode(age_grp, 
                              "75+" = "75  & above")) %>% 
  select(-se)

nhmspop19
```

\newpage

3. Join DOSM population and NHMS population
    -   since we want female on left side, the female population need to be in negative form
    -   the `female` also need to be in lower level
    -   and save the join dataset to R object, to be used later

```{r}
#| echo: fenced

join_pop19 <- full_join(dosmpop19, nhmspop19) %>% 
  arrange(gender, age_grp) %>% 
  filter(!age_grp %in% c("0-4", "5-9", "10-14")) %>% 
  mutate(population = case_when(gender == "Male" ~ population,
                                gender == "Female" ~ 0 - population), 
         gender = fct_relevel(gender, "Female"))

join_pop19
```

\newpage

4. we can plot the pyramid plot

```{r}
#| echo: fenced

join_pop19 %>% 
  ggplot(aes(x = age_grp, 
             y = population, 
             fill = interaction(gender, type))) + 
  geom_col(position = "dodge") + 
  scale_y_continuous(expand = c(0, 0),
                     labels = function(x) scales::label_comma()(abs(x)),  
                     breaks = scales::pretty_breaks()) +
  scale_fill_manual(values = hcl(h = c(15, 195, 15, 195), 
                                 c = 100, 
                                 l = 65, 
                                 alpha = c(.4, .4, 1, 1)), 
                    name = "") + 
  coord_flip() + 
  facet_wrap(. ~gender, 
             scales = "free_x", 
             strip.position = "bottom") + 
  theme_bw() + 
  theme(panel.border = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid.major.y = element_blank(), 
        legend.position = "bottom",
        panel.spacing.x = unit(0, "pt"), 
        strip.background = element_rect(colour = "black"))
```

