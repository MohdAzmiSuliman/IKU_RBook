# Complex Sampling Design in NHMS

```{r}
#| label: setup
#| echo: false

pacman::p_load(tidyverse)
```

## Why Complex Sampling Design?

Surveys are essential for understanding population characteristics, offering a more efficient and resource-friendly alternative to censuses. Censuses, aiming to collect data from every individual within a population, are historically resource-intensive. In contrast, surveys, whether conducted by governments or researchers, enable effective population inferences with less expenditure.

Simple random sampling, the traditional gold standard, offers a straightforward approach to population inference due to its readily implemented methodology and unbiased estimates. However, its effectiveness wanes in populations with high heterogeneity, potentially leading to underrepresentation of minority groups. This limitation necessitates the exploration of more intricate sampling designs, such as stratified sampling, despite their inherent complexities and potential for biased selection probabilities.

One of the significant advantages of complex sampling designs is their feasibility without a comprehensive population list, focusing instead on broader stratifications like specific localities, simplifying the sampling process.

### Benefits of Complex Sampling Design

The National Health and Morbidity Survey (NHMS), conducted by the Institute for Public Health (IPH), benefits extensively from complex sampling designs, showcasing several advantages:

1.  **Cost Efficiency**: By clustering samples within selected strata or areas, operational costs are notably reduced, obviating the need to cover extensive and potentially scattered geographical locations.

2.  **Enhanced Representativeness**: Stratification techniques ensure the sample accurately reflects specific subgroups or geographic areas, improving the survey's overall representativeness and reliability.

3.  **Data Analysis Advantages**: Complex sampling designs facilitate the adjustment of sampling weights, enabling the generation of accurate national or state-level estimates. Furthermore, they support comprehensive subgroup analyses, ensuring sufficient statistical power.

### Challenges in Implementing Complex Sampling Design

Despite their benefits, complex sampling designs require meticulous planning and sophisticated analytical techniques. These designs necessitate accounting for factors like clustering and weighting, demanding specialised expertise for both the sample's design and subsequent data analysis.

### Example: Sampling Probability of a Sabahan

Problem: Consider a hypothetical scenario within a diverse group of 100 people, composed of 60% Malay, 20% Chinese, 15% Indian, and an additional 5% from other ethnic backgrounds, including 1% Sabahan. How sure are we, than when we randomly select 10 people from the group, at least one of the 10 people will be a Sabahan?

Answer: To calculate the probability of selecting at least one Sabahan in a 10-person sample, one might initially consider the likelihood of not choosing a Sabahan and subtract this figure from 1. With 99 of the 100 individuals not being Sabahan, the probability of not selecting a Sabahan in a single attempt is 99/100. Over 10 independent selections, this probability becomes (99/100)\^10. Consequently, the probability of selecting at least one Sabahan is 1 - (99/100)\^10, equating to approximately 9.56%. This calculation suggests a close to 10% chance that the sample will include at least one Sabahan.

### Conclusion

Complex sampling designs present a pragmatic and efficient approach for conducting extensive surveys like the NHMS. They ensure a representative sample, optimise resource utilisation, and require careful planning and specialised statistical expertise for accurate population inferences.

\newpage

## Practical

In complex survey analysis using the `survey::` package in R, it's crucial to account for the design aspects of the survey beyond just the outcome variables and covariates. This includes specifying: 

```{r}
#| echo: false

tribble(~`Required Information/Specification`, ~`Common NHMS Variable Name`, 
        "Cluster IDs (PSU)", "EB ID", 
        "Strata", "State.Strata, State.wt", 
        "Sampling Weight", "ADW, weight_final, weight") %>% 
  gt::gt()
```


### Setup Project

1.  Setup your project
2.  Copy the NHMS dataset into the working directory
3.  Create Quarto document
    -   update the YAML metadata to make the document self-contained

```{r}
#| echo: true
#| eval: false

---
title: "Sesi 4 - NHMS"
format:
  html:
    embed-resources: true
---

```

### Analysis

#### Setup

0.  Understand the dataset context
    -   In this practical, the example was shown using NHMS NCD 2019's cholesterol dataset.
    -   Two outcome will be selected
        -   Categorical Type: known hypercholesterolaemia status (column `known_chol`)
        -   Numerical Type: capillary total cholesterol level (column `u303`)

@.  Import Dataset
    -   On the `Files` pane, click on the spps .sav file
    -   Select `Import Dataset...`
    -   Copy the code into the r code chunk
    -   add function `as_factor(_)` to convert labelled code

\newpage

```{r}
#| output: false
#| echo: fenced

library(tidyverse)
library(haven)

nhms19ds <- read_sav("nhms19ds.sav") %>% 
  as_factor()

nhms19ds
```


::: {.callout-note}
there are 40 columns in the dataset, hence the dataset is not shown here. 
:::



@. Briefly (or in detail, up to you), explore the dataset.
    -   Identify the outcome variable
        -   data type: numerical, character or factor?
        -   any missing data
    -   Identify the complex sampling related variable: 
        -   the cluster ids
        -   the strata 
        -   the sampling weight



::: {.callout-tip}
some packages and functions that offer a quick data exploration:  
    -   `skimr::` package: `skim(_)` function.  
    -   `summarytools::` package: `dfSummary(_)` function.  
:::


```{r}
#| eval: false
#| echo: fenced

library(skimr)

nhms19ds %>% 
  select(known_chol, u303) %>% 
  skim()
```


\newpage
\KOMAoptions{usegeometry, paper=landscape,pagesize}
\recalctypearea
\newgeometry{right=25mm,left=25mm,top=25mm,bottom=25mm}

```{r}
#| echo: false
#| layout-ncol: 2

library(labelled)
library(gt)

tibble(varname = names(nhms19ds), 
       varlab = get_variable_labels(nhms19ds)) %>% 
  unnest(cols = varlab, keep_empty = T) %>% 
  slice(., 1:20) %>% 
  gt() %>% 
  cols_label(varname = "Variable Name", 
             varlab = "Variable Label") %>%
  fmt_missing(missing_text = "_no label_")

tibble(varname = names(nhms19ds), 
       varlab = get_variable_labels(nhms19ds)) %>% 
  unnest(cols = varlab, keep_empty = T) %>% 
  slice(., 21:40) %>% 
  gt() %>% 
  cols_label(varname = "Variable Name", 
             varlab = "Variable Label") %>%
  fmt_missing(missing_text = "_no label_")
```

\newpage
\KOMAoptions{paper=portrait,pagesize}
\recalctypearea
\restoregeometry

```{r}
#| echo: false

library(skimr)

nhms19ds %>% 
  select(known_chol, u303) %>% 
  skim()
```

::: {.callout-warning}
- there are missing values in the outcome variable `known_chol`. while is it not a must to remove sample with no outcome, as the analysis will automatic remove sample with no outcome using `na.rm = T` parameter, it is advisable to remove any sample that do not have the outcome. 
- the outcome variable of capillary total cholesterol was in categorical type. we need to convert it to numerical type
:::


::: {.callout-tip}
later in complex sampling design analysis, the analysis accept the variable outcome (i.e. the `known_chol`) variable in either numeric or factor type. but binary type is preferable
:::


@. In this practical we will make some data wrangling
    -   remove missing outcome
    -   transform factor type to numerical binary type

```{r}
#| echo: fenced

nhms19ds <- nhms19ds %>% 
  as_factor() %>% 
  filter(!is.na(known_chol)) %>% 
  mutate(known_cholN = as.numeric(known_chol)-2,
         u303 = as.numeric(as.character(u303)))
```

\newpage

::: {.callout-note}
The variable `known_col` have there levels, which can be check using `levels(_)` function:  `levels(nhms19ds$known_chol)`. When converted to numeric using `as.numeric(_)` function, the `known_chol` value was either `1` (correspond to NA), `2` (correspond to No) and `3` (correspond to Yes), thus the value need to minus 2, so that `No` is correspond to value `0` and `Yes` is correspond with value `1`.  
\newline
the conversion can be check by looking at both the variable

```{r}
#| eval: false
#| echo: fenced

nhms19ds %>% 
  select(known_chol, known_cholN)
```
:::

@. Specifying the Complex Sampling Design
    -   Add options at the top of Quarto file
    -   These option is to handle in which if there is single PSU within strata or domains
    ```{r}
    #| echo: fenced
    
    library(survey)
    
    options(survey.lonely.psu = 'adjust', 
            survey.adjust.domain.lonely = TRUE)
    ```
    -   Unweighted Design
        -   cluster ids set as 1 (i.e., no clustering)
        -   weight as 1 (i.e., same probability)
    ```{r}
    #| echo: fenced
    
    nhms_unwdsg <- svydesign(id = ~1, 
                             weights = ~1, 
                             data = nhms19ds)
    ```
    \newpage
    -   we can use function `summary(_)` to view our complex sample design
    ```{r}
    summary(nhms_unwdsg)
    ```
    -   in unweighted design, the probability for sample range from 1 to 1.
    -   Weighted Design
        -   cluster `id` set as the PSU (commonly the variable `ebid`)
        -   `strata` set as the stratification. since most NHMS applied two stage of stratification, the strata must include both 1st stage and 2nd stage (commonly the variable `state_st`)
        -   `weights` set as the sampling weight
        -   Note that parameter `nest = T` to ensure that the cluster is nested within the specified strata
    ```{r}
    #| echo: fenced
    
    nhms_surdsg <- svydesign(id = ~ebid, 
                             strata = ~state_st, 
                             weights = ~wtfinal_ncd, 
                             data = nhms19ds, 
                             nest = T)
    ```
    -   we can use function `summary(_)` to view our complex sample design
    \newpage
    ```{r}
    #| echo: fenced
    options(width = 70) # the output width limit

    summary(nhms_surdsg)
    ```
    -   in weighted design summary, several info were given
        -   the sampling probabilities. in this dataset, each of the sample have probability from 0.00001 to 0.12
        -   the number of strata, number of sample in each of the strata and number of PSU (EB) in each strata. in this dataset, there are total 30 strata (13 states + 3 federal territories, with each state have 2 locality urban and rural).

#### Count the unweighted sample

1. To count the number of sample, we will use function `svymean(_`) from `survey::`. 
    -   the outcome variable can be either factor type, or if it in numerical type, it must be binary 0-1 number.
    -   to estimate the number of sample, we will use the unweighed design.
    -   the `x =` parameter must be in formula form with `~` (tilde) symbol before the variable name, i.e. `~known_chol`.

2. this is if we want to use the original factor type.

```{r}
#| echo: fenced

svytotal(x = ~known_chol, 
         design = nhms_unwdsg, 
         na.rm = T)
```

3. this is if we want to use the converted to binary 0-1 numerical type. noticed the output differences.

```{r}
#| echo: fenced

svytotal(x = ~known_cholN, 
         design = nhms_unwdsg, 
         na.rm = T)
```


::: {.callout-note}
Note 1: noticed that parameter `na.rm =` were set as T (TRUE). this is so that any sample with missing at parameter `x =` (i.e. the `known_chol`) will be removed.  
\newline
Note 2: From this point forward, I'll use `known_cholN` variable (the binary 0-1 numerical type) as the outcome. You are feel free to use the original factor type, and explore as you wish.
:::

#### Estimating the estimated population

1. to estimate total number of population that have the outcome (i.e., `known_cholN`), same formula is used, with changes at the design used, i.e. the weighted design

```{r}
#| echo: fenced

svytotal(x = ~known_cholN, 
         design = nhms_surdsg, 
         na.rm = T)
```


#### Estimating Prevalence

0. Estimating the prevalence using the function of `svymean(_)` from `survey::` package.
    -   if the outcome variable is factor type, both original factor type and converted numerical type can be used.
        -   if original factor type is used, prevalence for both `No` and `Yes` will be estimated.
        -   if the outcome have three or more levels, using original factor type is preferable.
        -   when using the binary 0-1 numerical type (i.e., the `known_cholN`), `svymean(_)` will calculate prevalence by calculating how many `1` since `0` does not have value.

1. Using function `svymean(_)` to calculate 

```{r}
#| echo: fenced

svymean(x = ~known_cholN, 
        design = nhms_surdsg, 
        na.rm = T)
```

\newpage

#### Estimating Confidence Interval for Prevalence

1. To calculate the confidence interval for prevalence, function `svyciprop(_)` from package `survey::` will be used.
    -   Generally, a generic function `confint(_)` can be used to calculate the confident interval for model parameter. 
    -   In R however, the function will treat proportion as mean of binary outcomes. While treating proportion as mean of binary outcomes is reasonable accepted to calculate the prevalence, however, when calculate the CI, it is preferable to treat apply logit transformation and transformed back to the original scale
    -   the default method used in `svyciprop(_)` function is "logit"
    -   however, to replicate result from SPSS and SUDAAN, the method parameter need to change to "xlogit"
:::


```{r}
#| echo: fenced

svyciprop(formula = ~known_cholN, 
          design = nhms_surdsg, 
          method = "xl") %>% 
  attr(., "ci")
```
::: {.callout-note}
- function `attr(_)` is used to pull the attribute from the object (i.e., the output of the `svyciprop(_)` function), while the parameter `"ci"` in the `attr(_, "ci")` function is to pull the CI from the `svyciprop(_)`
:::


#### Estimating the Unweighted Sample Proportion


::: {.callout-tip}
Can you calculated the sample proportion using the same function?.  

Hint:  

1. Sample Proportion = Unweighted Proportion.
2. Unweighted design vs. Weighted design.
:::


#### Estimating by Subpopulation

1. To estimates by subpopulation, we use `svyby(_)` function

2. Estimating the unweighted count by state
    -   Don't forget to use the unweighted design

```{r}
#| echo: fenced

svyby(formula = ~known_cholN, 
      by = ~strata_gp, 
      design = nhms_unwdsg, 
      FUN = svytotal, 
      na.rm.all = T)

```

3. Estimating the estimated population by state

```{r}
#| echo: fenced

svyby(formula = ~known_cholN, 
      by = ~strata_gp, 
      design = nhms_surdsg, 
      FUN = svytotal, 
      na.rm.all = T)
```


4. Estimating the prevalence by state

```{r}
#| echo: fenced

svyby(formula = ~known_cholN, 
      by = ~strata_gp, 
      design = nhms_unwdsg, 
      FUN = svymean, 
      na.rm.all = T)
```

5. Estimating the prevalence CI by state.
    - unfortunately, `svyciprop(_)` can't be used with `svyby(_)` function.
    - to estimate the CI, we need to subset the sample, to only the sub-population.

::: {.callout-warning}
This however, will affect the degree of freedom (df). thus, we need to specified the df in the subset analysis, using the df of the overall design. to achieve this, add parameter `df = degf(design)`, where the design is the overall design
:::

```{r}
#| echo: fenced

nhms_surdsg_urban <- subset(nhms_surdsg, 
                            strata_gp == "Urban") 

svyciprop(formula = ~known_cholN, 
          design = nhms_surdsg_urban, 
          method = "xl", 
          df = degf(nhms_surdsg)) %>% 
  attr(., "ci")
```
\noindent alternatively, we can create custom function \newline (the custom function code is shown next page) 

```{r}
#| echo: false

# create a svyby-like function specific for svyciprop
svyciprop_by <- function(x, by, design, 
                         df = NULL, method = NULL) {
  # extract the levels in by
  by_var <- all.vars(by)[1]
  by_data <- model.frame(by, data = design$variables)
  by_levels <- sort(unique(by_data[[by_var]]))
 
  # run the svyciprop() functions on each levels in by
  calculate_ci <- function(stratum) {
    subset_design <- 
      subset(design, 
             design$variables[[by_var]] == stratum)
    # Use provided df or default to subset design df
    df_to_use <- if (is.null(df)) degf(subset_design) else df
    result <- svyciprop(x, design = subset_design, 
                        method = method, df = df_to_use)
    return(attr(result, "ci"))
  }
  
  # tabulate the result
  ci_results <- lapply(by_levels, calculate_ci)
  results <- data.frame(subset = by_levels, 
                        ci = do.call(rbind, ci_results))

  return(results)
}
```


```{r}
#| echo: fenced

svyciprop_by(x = ~known_cholN, by = ~strata_gp, 
             design = nhms_surdsg, 
             df = degf(nhms_surdsg), method = "xl")
```

\newpage 

\noindent the custom function code

```{r}
#| echo: fenced

# create a svyby-like function specific for svyciprop
svyciprop_by <- function(x, by, design, 
                         df = NULL, method = NULL) {
  # extract the levels in by
  by_var <- all.vars(by)[1]
  by_data <- model.frame(by, data = design$variables)
  by_levels <- sort(unique(by_data[[by_var]]))
 
  # run the svyciprop() functions on each levels in by
  calculate_ci <- function(stratum) {
    subset_design <- 
      subset(design, 
             design$variables[[by_var]] == stratum)
    # Use provided df or default to subset design df
    df_to_use <- if (is.null(df)) degf(subset_design) else df
    result <- svyciprop(x, design = subset_design, 
                        method = method, df = df_to_use)
    return(attr(result, "ci"))
  }
  
  # tabulate the result
  ci_results <- lapply(by_levels, calculate_ci)
  results <- data.frame(subset = by_levels, 
                        ci = do.call(rbind, ci_results))

  return(results)
}
```

\vspace{10pt}

::: {.callout-note}
this custom function can be simplified, but i make it more general so it can be use to other too.
:::


#### Total Sample and Estimated Population

\noindent Can you try calculate the total sample? Using the example from calculating the total number sample with the outcome. 

\noindent The tutorial on estimated total population will be cover in Bonus II: Population Pyramid part

## Bonus I: Regression (Linear Regression & Logistic Regression)

### Logistic Regression

#### Simple Logistic Regression

```{r}
svyglm(known_chol ~ strata_gp, 
       nhms_surdsg, 
       family = quasibinomial) %>% 
  summary()
```


#### Multiple Logistic Regression

```{r}
svyglm(known_chol ~ strata_gp + A2101 + A2108_3grp, 
       nhms_surdsg, 
       family = quasibinomial) %>% 
  summary()
```



### Linear Regression

#### Simple Linear Regression

```{r}
svyglm(u303 ~ strata_gp, 
       nhms_surdsg, 
       family = gaussian) %>% 
  summary()
```

#### Multiple Linear Regression

```{r}
svyglm(u303 ~ strata_gp+ A2101 + A2108_3grp, 
       nhms_surdsg, 
       family = gaussian) %>% 
  summary()
```

## Bonus II: Mapping the Prevalence

## Bonus III: Population Pyramid:


